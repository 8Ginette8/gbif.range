% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/wsl_gbif.R
\name{wsl_gbif}
\alias{wsl_gbif}
\title{Massively download and filter GBIF observations for sound spatial analyses}
\usage{
wsl_gbif(
  sp_name = NULL,
  conf_match = 90,
  geo = NULL,
  grain = 1000,
  duplicates = FALSE,
  absences = FALSE,
  no_xy = FALSE,
  basis = c("OBSERVATION", "HUMAN_OBSERVATION", "MACHINE_OBSERVATION",
    "MATERIAL_SAMPLE", "PRESERVED_SPECIMEN", "FOSSIL_SPECIMEN", "LIVING_SPECIMEN",
    "LITERATURE", "UNKNOWN"),
  add_infos = NULL,
  time_period = c(1000, 3000),
  identic_xy = FALSE,
  wConverted_xy = FALSE,
  centroids = FALSE,
  ntries = 10,
  error.skip = TRUE,
  ...
)
}
\arguments{
\item{sp_name}{Character. Scientific name to run an online search
(i.e. with GBIF-API) for species observations. Works also for genus and higher taxa
levels.}

\item{conf_match}{Numeric from 0 to 100. Determine the confidence threshold of match
of 'sp_name' with the GBIF backbone taxonomy. Default is 90.}

\item{geo}{Object of class 'Extent', 'SpatExtent', 'SpatialPolygon', 'SpatialPolygonDataframe',
or 'SpaVector' (WGS84) to define the study's area extent. Default is NULL i.e. the whole globe.}

\item{grain}{Numeric. Specify in meters the study resolution. Used to
filter gbif records (x2) according to their uncertainties and number of coordinate
decimals. Records with no information on coordinate uncertainties (column
'coordinateUncertaintyInMeters') are be kept by default. See details.}

\item{duplicates}{Logical. Should duplicated records be kept?}

\item{absences}{Logical. Should absence records be kept?}

\item{no_xy}{Logical. Default is FALSE i.e. only records with coordinates are
downloaded. If TRUE, only records with no coordinates are downloaded.}

\item{basis}{Character. Which basis of records should be selected?
Default is all i.e. c("OBSERVATION", "HUMAN_OBSERVATION", "MACHINE_OBSERVATION",
"MATERIAL_SAMPLE", "PRESERVED_SPECIMEN", "FOSSIL_SPECIMEN", "LIVING_SPECIMEN", "LITERATURE",
"UNKNOWN"). Description may be found here: https://docs.gbif.org/course-data-use/en/basis-of-record.html}

\item{add_infos}{Character. Infos that may be added to the default output information.
List of IDs may be found at: https://www.gbif.org/developer/occurrence.
Default IDs contain 'taxonKey', 'scientificName', 'acceptedTaxonKey',
'acceptedScientificName', 'individualCount', 'decimalLatitude', 'decimalLongitude',
'basisOfRecord', 'coordinateUncertaintyInMeters', 'country', 'year', 'datasetKey', 
'institutionCode', 'publishingOrgKey', 'taxonomicStatus' and 'taxonRank'.}

\item{time_period}{Numerical vector. Observations will be downloaded according to the chosen
year range. Default is c(1000,3000). Observations with year = NA are kept by default.}

\item{identic_xy}{Logical. Should records with identical xy be kept?}

\item{wConverted_xy}{Logical. Should incorrectly lon/lat converted xy be kept?
Uses `cd_ddmm` from 'CoordinateCleaner' R package.}

\item{centroids}{Logical. Should species records from raster centroids be kept?
Uses `cd_round` from 'CoordinateCleaner' R package.}

\item{ntries}{Numeric. In case of failure from GBIF server or within the rgbif package, how many
download attempts should the function request? Default is '10' with a 2 seconds interval
between tries. If attempts failed, an empty data.frame is return by default.}

\item{error.skip}{Logical. Should the search process continues if ntries failed ?}

\item{...}{Additonnal parameters for the function cd_round() of CoordinateCleaner.}
}
\value{
Object of class data.frame with requested GBIF information. Although the function
works accurately, error outputs might still occur depending on the 'sp_name' used.
Therefore, default information detailed in 'add_infos' is stored so that sanity checks
may still be applied afterwards. Although crucial preliminary checks of species records
are done by the function, addtional post exploration with the CoordinateCleaner R
package is still highly recommended.
}
\description{
Implement an user-friendly workflow to download and clean gbif taxa observations.
The function uses the rgbif R package but (1) implements the same search result 
found if www.gbif.org is employed i.e., based on the input taxa name, all species
records related to its accepted name and synonyms are extracted. The function
also (2) bypasses rgbif hard limit on the number of records (100'000 max).
For this purpose, a dynamic moving window is created and used across the geographic
extent defined by the user. This window automatically fragments the specified
study area in succesive tiles of different sizes, until all tiles include < 100'000
observations. The function also (3) automatically applies a post-filtering of
observations based on the chosen resolution of the study/analysis and by partly
employing the CoordinateCleaner R package. Filtering options may be chosen and
involve several choices: study's extent, removal of duplicates, removal of absences,
basis of records selection, removal of invalid/uncertain xy coordinates (WGS84), time
period selection and removal of raster centroids. By default, the argument
hasGeospatialIssue in occ_search() (implemented rgbif function) is set to FALSE.
}
\details{
Argument `grain` used for two distinct gbif records filtering. (1) Records filtering
according to gbif 'coordinateUncertaintyInMeters'; every records uncertainty > grain/2
are removed. Note: Records with no information on coordinate uncertainties are kept by
default. (2) Records filtering according to the number of longitude/latitude decimals;
if 110km < grain <= 11km, lon/lat with >= 1 decimal are kept, if 11km < grain <= 1100m,
lon/lat with >= 2 decimals kept; if 1100m < grain <= 110m, lon/lat with >= 3 decimals
are kept; if 110m < grain <= 11m, lon/lat with >= 4 decimals are kept;
if 11m < grain <= 1.1m, lon/lat with >= 5 decimals are kept etc...
}
\examples{

# Load maptools for the map world
library(maptools)
data(wrld_simpl)

# Load the Alps Extend
data(geo_dat)

# Downloading worldwide the observations of Panthera tigris
test1 = wsl_gbif("Panthera tigris",basis=c("OBSERVATION","HUMAN_OBSERVATION"))
plot(wrld_simpl)
points(test1[,c("decimalLongitude","decimalLatitude")],pch=20,col="#238b4550",cex=4)

# Downloading in the Alps the observations of Cypripedium calceolus (with a 100m grain and
# by adding the 'issues' column)
test2 = wsl_gbif("Cypripedium calceolus", geo = shp.lonlat, grain = 100, add_infos = c("issue"))
plot(shp.lonlat)
points(test2[,c("decimalLongitude","decimalLatitude")],pch=20,col="#238b4550",cex=1)

# Downloading worlwide the observations of Ailuropoda melanoleuca (with a 100km grain, after 1990
# and by keeping duplicates and by adding the name of the person who collected the panda records)
test3 = wsl_gbif("Ailuropoda melanoleuca", grain = 100000 , duplicates = TRUE,
    time_period = c(1990,3000), add_infos = c("recordedBy","issue"))
plot(wrld_simpl)
points(test3[,c("decimalLongitude","decimalLatitude")],pch=20,col="#238b4550",cex=4)

# Downloading worlwide the observations of Phascolarctos cinereus (with a 1km grain, after 1980,
# and keeping raster centroids)
test4 = wsl_gbif("Phascolarctos cinereus", grain = 1000,
    time_period = c(1990,3000), centroids = TRUE)

}
\references{
Chauvier, Y., Thuiller, W., Brun, P., Lavergne, S., Descombes, P., Karger, D. N., ... & Zimmermann,
N. E. (2021). Influence of climate, soil, and land cover on plant species distribution in the
European Alps. Ecological monographs, 91(2), e01433. 10.1002/ecm.1433

Chamberlain, S., Oldoni, D., & Waller, J. (2022). rgbif: interface to the global biodiversity
information facility API. 10.5281/zenodo.6023735

Zizka, A., Silvestro, D., Andermann, T., Azevedo, J., Duarte Ritter, C., Edler, D., ... & Antonelli,
A. (2019). CoordinateCleaner: Standardized cleaning of occurrence records from biological collection
databases. Methods in Ecology and Evolution, 10(5), 744-751. 10.1111/2041-210X.13152

Hijmans, Robert J. "terra: Spatial Data Analysis. R Package Version 1.6-7." (2022). Terra - CRAN
}
\seealso{
The (1) rgbif and (2) CoordinateCelaner packages for additional and more general
approaches on (1) downloading GBIF observations and (2) post-filetering those.
}
