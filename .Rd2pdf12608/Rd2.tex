\documentclass[a4paper]{book}
\usepackage[times,inconsolata,hyper]{Rd}
\usepackage{makeidx}
\usepackage[utf8]{inputenc} % @SET ENCODING@
% \usepackage{graphicx} % @USE GRAPHICX@
\makeindex{}
\begin{document}
\chapter*{}
\begin{center}
{\textbf{\huge wsl.gbif}}
\par\bigskip{\large \today}
\end{center}
\inputencoding{utf8}
\ifthenelse{\boolean{Rd@use@hyper}}{\hypersetup{pdftitle = {wsl.gbif: A toolbox to efficiently download and filter large GBIF observational datasets for sound spatial analyses}}}{}\begin{description}
\raggedright{}
\item[Type]\AsIs{Package}
\item[Title]\AsIs{A toolbox to efficiently download and filter large GBIF observational datasets for sound spatial analyses}
\item[Version]\AsIs{0.1.0}
\item[Depends]\AsIs{R (>= 4.0.0), raster, terra,  rgbif, CoordinateCleaner}
\item[Description]\AsIs{Package aiming at easing the workflow of retrieving GBIF observations at large spatial scale for all species accepted names and synonyms, and filtering them according to the specific scale of an analysis.}
\item[License]\AsIs{GPL (>=3)}
\item[BugReports]\AsIs{}\url{https://github.com/8Ginette8/wsl.gbif/issues}\AsIs{}
\item[Encoding]\AsIs{UTF-8}
\item[Maintainer]\AsIs{Yohann Chauvier, @: yohann.chauvier@wsl.ch}
\item[LazyData]\AsIs{true}
\item[RoxygenNote]\AsIs{7.1.2}
\item[Authors]\AsIs{Yohann Chauvier [cre,aut] (https://orcid.org/0000-0001-9399-3192)}
\item[Collate]\AsIs{'make_tiles.R'
'wsl_gbif.R'
'wsl_taXnames.R'}
\end{description}
\Rdcontents{\R{} topics documented:}
\inputencoding{utf8}
\HeaderA{make\_tiles}{Create a specific number of tiles based on an extent}{make.Rul.tiles}
%
\begin{Description}\relax
Not to be called directly by the user
\end{Description}
%
\begin{Usage}
\begin{verbatim}
make_tiles(geo, Ntiles, meta = TRUE)
\end{verbatim}
\end{Usage}
%
\begin{Author}\relax
Yohann Chauvier
\end{Author}
\inputencoding{utf8}
\HeaderA{wsl\_gbif}{Massively download and filter GBIF observations for sound spatial analyses}{wsl.Rul.gbif}
%
\begin{Description}\relax
Implement an user-friendly workflow to download and clean gbif taxa observations.
The function uses the rgbif R package but (1) implements the same search result 
found if www.gbif.org is employed i.e., based on the input taxa name, all species
records related to its accepted name and synonyms are extracted. The function
also (2) bypasses rgbif hard limit on the number of records (100'000 max).
For this purpose, a dynamic moving window is created and used across the geographic
extent defined by the user. This window automatically fragments the specified
study area in succesive tiles of different sizes, until all tiles include < 100'000
observations. The function also (3) automatically applies a post-filtering of
observations based on the chosen resolution of the study/analysis and by partly
employing the CoordinateCleaner R package. Filtering options may be chosen and
involve several choices: study's extent, removal of duplicates, removal of absences,
basis of records selection, removal of invalid/uncertain xy coordinates (WGS84), time
period selection and removal of raster centroids. By default, the argument
hasGeospatialIssue in occ\_search() (implemented rgbif function) is set to FALSE.
To get the custom DOI of the downloaded GBIF data, the derived\_dataset() function
from the rgbif package must be used with the column 'datasetKey' of one or several
outputs.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
wsl_gbif(
  sp_name = NULL,
  conf_match = 90,
  geo = NULL,
  grain = 1000,
  duplicates = FALSE,
  absences = FALSE,
  no_xy = FALSE,
  basis = c("OBSERVATION", "HUMAN_OBSERVATION", "MACHINE_OBSERVATION",
    "MATERIAL_SAMPLE", "PRESERVED_SPECIMEN", "FOSSIL_SPECIMEN", "LIVING_SPECIMEN",
    "LITERATURE", "UNKNOWN"),
  add_infos = NULL,
  time_period = c(1000, 3000),
  identic_xy = FALSE,
  wConverted_xy = FALSE,
  centroids = FALSE,
  ntries = 10,
  error.skip = TRUE,
  ...
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{sp\_name}] Character. Scientific name to run an online search
(i.e. with GBIF-API) for species observations. Works also for genus and higher taxa
levels.

\item[\code{conf\_match}] Numeric from 0 to 100. Determine the confidence threshold of match
of 'sp\_name' with the GBIF backbone taxonomy. Default is 90.

\item[\code{geo}] Object of class 'Extent', 'SpatExtent', 'SpatialPolygon', 'SpatialPolygonDataframe',
or 'SpaVector' (WGS84) to define the study's area extent. Default is NULL i.e. the whole globe.

\item[\code{grain}] Numeric. Specify in meters the study resolution. Used to
filter gbif records (x2) according to their uncertainties and number of coordinate
decimals. Records with no information on coordinate uncertainties (column
'coordinateUncertaintyInMeters') are be kept by default. See details.

\item[\code{duplicates}] Logical. Should duplicated records be kept?

\item[\code{absences}] Logical. Should absence records be kept?

\item[\code{no\_xy}] Logical. Default is FALSE i.e. only records with coordinates are
downloaded. If TRUE, only records with no coordinates are downloaded.

\item[\code{basis}] Character. Which basis of records should be selected?
Default is all i.e. c("OBSERVATION", "HUMAN\_OBSERVATION", "MACHINE\_OBSERVATION",
"MATERIAL\_SAMPLE", "PRESERVED\_SPECIMEN", "FOSSIL\_SPECIMEN", "LIVING\_SPECIMEN", "LITERATURE",
"UNKNOWN"). Description may be found here: https://docs.gbif.org/course-data-use/en/basis-of-record.html

\item[\code{add\_infos}] Character. Infos that may be added to the default output information.
List of IDs may be found at: https://www.gbif.org/developer/occurrence.
Default IDs contain 'taxonKey', 'scientificName', 'acceptedTaxonKey',
'acceptedScientificName', 'individualCount', 'decimalLatitude', 'decimalLongitude',
'basisOfRecord', 'coordinateUncertaintyInMeters', 'country', 'year', 'datasetKey', 
'institutionCode', 'publishingOrgKey', 'taxonomicStatus' and 'taxonRank'.

\item[\code{time\_period}] Numerical vector. Observations will be downloaded according to the chosen
year range. Default is c(1000,3000). Observations with year = NA are kept by default.

\item[\code{identic\_xy}] Logical. Should records with identical xy be kept?

\item[\code{wConverted\_xy}] Logical. Should incorrectly lon/lat converted xy be kept?
Uses `cd\_ddmm` from 'CoordinateCleaner' R package.

\item[\code{centroids}] Logical. Should species records from raster centroids be kept?
Uses `cd\_round` from 'CoordinateCleaner' R package.

\item[\code{ntries}] Numeric. In case of failure from GBIF server or within the rgbif package, how many
download attempts should the function request? Default is '10' with a 2 seconds interval
between tries. If attempts failed, an empty data.frame is return by default.

\item[\code{error.skip}] Logical. Should the search process continues if ntries failed ?

\item[\code{...}] Additonnal parameters for the function 'cd\_round' of the 'CoordinateCleaner'
R package.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
Argument `grain` used for two distinct gbif records filtering. (1) Records filtering
according to gbif 'coordinateUncertaintyInMeters'; every records uncertainty > grain/2
are removed. Note: Records with no information on coordinate uncertainties are kept by
default. (2) Records filtering according to the number of longitude/latitude decimals;
if 110km < grain <= 11km, lon/lat with >= 1 decimal are kept, if 11km < grain <= 1100m,
lon/lat with >= 2 decimals kept; if 1100m < grain <= 110m, lon/lat with >= 3 decimals
are kept; if 110m < grain <= 11m, lon/lat with >= 4 decimals are kept;
if 11m < grain <= 1.1m, lon/lat with >= 5 decimals are kept etc...
\end{Details}
%
\begin{Value}
Object of class 'data.frame' with requested GBIF information. Although the function
works accurately, error outputs might still occur depending on the 'sp\_name' used.
Therefore, default information detailed in 'add\_infos' is stored so that sanity checks
may still be applied afterwards. Although crucial preliminary checks of species records
are done by the function, addtional post exploration with the 'CoordinateCleaner' R
package is still highly recommended.
\end{Value}
%
\begin{Author}\relax
Yohann Chauvier
\end{Author}
%
\begin{Examples}
\begin{ExampleCode}

# Necessary libraries
#library(raster)
#library(terra)
#library(rgbif)
#library(CoordinateCleaner)

# Load the Alps Extend
data(AlpineConvention_lonlat)

# Downloading worldwide the observations of Panthera tigris
test1 = wsl_gbif("Panthera tigris")

# Downloading in the Alps the observations of Cypripedium calceolus (with a 100m grain and
# by adding the 'issues' column)
test3 = wsl_gbif("Cypripedium calceolus", geo = shp.lonlat, grain = 100, add_infos = c("issue"))
plot(shp.lonlat)
points(test1[,c("decimalLongitude","decimalLatitude")],pch=20,col="#238b4550",cex=1)

# Downloading worlwide the observations of Ailuropoda melanoleuca (with a 100km grain, after
# 1990 and by keeping duplicates and by adding the name of the person who collected the species records)
test3 = wsl_gbif("Ailuropoda melanoleuca", grain = 100000 , duplicates = TRUE,
    time_period = c(1990,3000), add_infos = c("recordedBy","issue"))

# Downloading worlwide the observations of Phascolarctos cinereus (with a 1km grain, after 1980,
# and keeping raster centroids)
test4 = wsl_gbif("Phascolarctos cinereus", grain = 1000,
    time_period = c(1990,3000), centroids = TRUE)

# Just an example on how to retrieve the DOI for the first downloaded dataset using
# derived_dataset() from the rgbif R package. Note that multiple datasets may be combined
# and derived_dataset() used once to only obtain one unique DOI.
d.target = table(test1$datasetKey)
d.summary = data.frame(datasetKey = names(d.target),count = as.numeric(d.target))
rgbif::derived_dataset(d.summary,"GBIF_test",
    "Filetred and cleaned based on CoordinateCleaner",source_url="https://example.com/",
    user="your_gbif_user",pwd="your_gbif_password")


\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{wsl\_taXnames}{Retrieve from GBIF all scientific names of a specific Taxa}{wsl.Rul.taXnames}
%
\begin{Description}\relax
Allows to extract from the gbif backbone taxonomy all names from an input species name
(accepted, synonyms, children, related...).
\end{Description}
%
\begin{Usage}
\begin{verbatim}
wsl_taXnames(sp_name = NULL, conf_match = 90, all = FALSE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{sp\_name}] Character. Species name from which the user wants to retrieve all existing GBIF names

\item[\code{conf\_match}] Numeric. From 0 to 100. Determine the confidence
threshold of match of 'sp\_name' with the GBIF backbone taxonomy. Default is 90.

\item[\code{all}] Logical. Default is FALSE. Should all species names be retrieved or only
the accepted name and its synonyms?
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A data.frame with two columns: (1) Names and (2) Backbone Taxonomy Status
\end{Value}
%
\begin{Author}\relax
Yohann Chauvier
\end{Author}
%
\begin{Examples}
\begin{ExampleCode}
wsl_taXnames("Cypripedium calceolus",all=FALSE)
wsl_taXnames("Cypripedium calceolus",all=TRUE)

\end{ExampleCode}
\end{Examples}
\printindex{}
\end{document}
